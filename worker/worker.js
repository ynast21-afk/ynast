/**
 * ==================================================
 * kStreamer Upload Worker v2.1.0 (Puppeteer + Direct B2)
 * ==================================================
 *
 * Puppeteerë¥¼ ì‚¬ìš©í•˜ì—¬ skbj.tvì— ë¡œê·¸ì¸í•˜ê³ 
 * ì˜ìƒì˜ ì‹¤ì œ ì†ŒìŠ¤ URLì„ ì¶”ì¶œí•œ ë’¤
 * ë‹¤ìš´ë¡œë“œ â†’ B2 ì§ì ‘ ì—…ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
 *
 * ì„¤ì •:
 *   1. cd worker && npm install
 *   2. .env íŒŒì¼ ì„¤ì • (ì•„ë˜ ì°¸ì¡°)
 *   3. node worker.js
 *
 * í•„ìš”í•œ .env ë³€ìˆ˜:
 *   SITE_URL=http://localhost:3000
 *   ADMIN_TOKEN=your-admin-token
 *   WORKER_ID=worker-pc-1
 *   POLL_INTERVAL_MS=5000
 *   SKBJ_EMAIL=your-email
 *   SKBJ_PASSWORD=your-password
 *   B2_APPLICATION_KEY_ID=your-b2-key-id
 *   B2_APPLICATION_KEY=your-b2-key
 *   B2_BUCKET_ID=your-bucket-id
 *   B2_BUCKET_NAME=your-bucket-name
 */

require('dotenv').config()
// Also try .env.local (the project's main env file)
require('dotenv').config({ path: require('path').join(__dirname, '.env.local') })
const puppeteer = require('puppeteer')
const https = require('https')
const http = require('http')
const fs = require('fs')
const path = require('path')
const crypto = require('crypto')
const { execSync } = require('child_process')
const { claimJob, updateJob, getQueue, checkJobCancelled, getStreamers, getStreamer, addVideo, updateStreamer, setDocument } = require('./firebase-direct')

// ============================================
// Configuration
// ============================================
const SITE_URL = process.env.SITE_URL || process.env.NEXT_PUBLIC_SITE_URL || 'http://localhost:3000'
const ADMIN_TOKEN = process.env.ADMIN_TOKEN || process.env.ADMIN_API_SECRET
const WORKER_ID = process.env.WORKER_ID || `worker-${crypto.randomBytes(3).toString('hex')}`
const POLL_INTERVAL_MS = parseInt(process.env.POLL_INTERVAL_MS || '5000')
const MAX_CONCURRENT_JOBS = parseInt(process.env.MAX_CONCURRENT_JOBS || '3')
const TEMP_DIR = path.join(__dirname, 'temp')

const SKBJ_EMAIL = process.env.SKBJ_EMAIL
const SKBJ_PASSWORD = process.env.SKBJ_PASSWORD

// B2 direct credentials (no API route needed)
const B2_KEY_ID = process.env.B2_APPLICATION_KEY_ID
const B2_KEY = process.env.B2_APPLICATION_KEY
const B2_BUCKET_ID = process.env.B2_BUCKET_ID
const B2_BUCKET_NAME = process.env.B2_BUCKET_NAME

if (!ADMIN_TOKEN) {
    console.error('âŒ ADMIN_TOKEN is required.')
    process.exit(1)
}
if (!SKBJ_EMAIL || !SKBJ_PASSWORD) {
    console.warn('âš ï¸ SKBJ_EMAIL/SKBJ_PASSWORD ë¯¸ì„¤ì • â€” URL ëª¨ë“œ ì‚¬ìš© ë¶ˆê°€ (ë¡œì»¬ íŒŒì¼ ëª¨ë“œë§Œ ê°€ëŠ¥)')
}
if (!B2_KEY_ID || !B2_KEY || !B2_BUCKET_ID) {
    console.error('âŒ B2_APPLICATION_KEY_ID, B2_APPLICATION_KEY, and B2_BUCKET_ID are required.')
    process.exit(1)
}

// Ensure temp dir exists
if (!fs.existsSync(TEMP_DIR)) {
    fs.mkdirSync(TEMP_DIR, { recursive: true })
}

console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   kStreamer Upload Worker v2.1.0         â•‘
â•‘   (Puppeteer + Direct B2 Upload)        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Worker ID: ${WORKER_ID.padEnd(28)}â•‘
â•‘  Site URL:  ${SITE_URL.padEnd(28)}â•‘
â•‘  B2 Bucket: ${(B2_BUCKET_NAME || '').padEnd(28)}â•‘
â•‘  Poll:      ${(POLL_INTERVAL_MS + 'ms').padEnd(28)}â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`)

// ============================================
// B2 Direct Auth & Upload (no API route needed)
// ============================================
let b2Auth = null
let b2AuthTime = 0

async function authorizeB2() {
    // Reuse auth for 20 minutes
    if (b2Auth && Date.now() - b2AuthTime < 20 * 60 * 1000) {
        return b2Auth
    }

    console.log('   ğŸ” Authorizing with B2...')
    const credentials = Buffer.from(`${B2_KEY_ID}:${B2_KEY}`).toString('base64')

    const res = await fetch('https://api.backblazeb2.com/b2api/v2/b2_authorize_account', {
        headers: { 'Authorization': `Basic ${credentials}` }
    })

    if (!res.ok) {
        const text = await res.text()
        throw new Error(`B2 auth failed (${res.status}): ${text}`)
    }

    b2Auth = await res.json()
    b2AuthTime = Date.now()
    console.log('   âœ… B2 authorized')
    return b2Auth
}

async function getB2UploadUrl(auth) {
    const res = await fetch(`${auth.apiUrl}/b2api/v2/b2_get_upload_url`, {
        method: 'POST',
        headers: {
            'Authorization': auth.authorizationToken,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({ bucketId: B2_BUCKET_ID })
    })

    if (!res.ok) {
        const text = await res.text()
        throw new Error(`B2 get upload URL failed (${res.status}): ${text}`)
    }

    return res.json()
}

// Upload a single part of a large file
async function uploadSinglePart(auth, fileId, filePath, partNum, offset, length, fileSize) {
    // Get upload URL for this part
    const partUrlRes = await fetch(`${auth.apiUrl}/b2api/v2/b2_get_upload_part_url`, {
        method: 'POST',
        headers: {
            'Authorization': auth.authorizationToken,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({ fileId })
    })
    if (!partUrlRes.ok) {
        throw new Error(`Failed to get part upload URL: ${await partUrlRes.text()}`)
    }
    const partUrlData = await partUrlRes.json()

    // Read part from file
    const buffer = Buffer.alloc(length)
    const fd = fs.openSync(filePath, 'r')
    fs.readSync(fd, buffer, 0, length, offset)
    fs.closeSync(fd)

    const sha1 = crypto.createHash('sha1').update(buffer).digest('hex')

    const uploadRes = await fetch(partUrlData.uploadUrl, {
        method: 'POST',
        headers: {
            'Authorization': partUrlData.authorizationToken,
            'Content-Length': length.toString(),
            'X-Bz-Part-Number': partNum.toString(),
            'X-Bz-Content-Sha1': sha1,
        },
        body: buffer,
    })
    if (!uploadRes.ok) {
        const errText = await uploadRes.text()
        throw new Error(`Part ${partNum} upload failed: ${errText}`)
    }
    return { partNum, sha1 }
}

// Large file upload (for files > 100MB) â€” parallel part uploads (2 at a time)
async function uploadLargeFile(auth, filePath, b2FileName, contentType, jobId = null) {
    const fileSize = fs.statSync(filePath).size
    const PART_SIZE = 50 * 1024 * 1024 // 50MB parts
    const partCount = Math.ceil(fileSize / PART_SIZE)
    const PARALLEL_PARTS = 2 // Upload 2 parts simultaneously

    console.log(`   ğŸ“¦ Large file upload: ${partCount} parts of ${(PART_SIZE / 1024 / 1024).toFixed(0)}MB each (${PARALLEL_PARTS} parallel)`)

    // Step 1: Start large file
    const startRes = await fetch(`${auth.apiUrl}/b2api/v2/b2_start_large_file`, {
        method: 'POST',
        headers: {
            'Authorization': auth.authorizationToken,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            bucketId: B2_BUCKET_ID,
            fileName: b2FileName,
            contentType,
        })
    })
    if (!startRes.ok) {
        const text = await startRes.text()
        throw new Error(`B2 start large file failed: ${text}`)
    }
    const { fileId } = await startRes.json()
    console.log(`   ğŸ“„ Large file ID: ${fileId}`)

    const partSha1s = new Array(partCount) // indexed by partNum-1
    let completedParts = 0

    try {
        // Step 2: Upload parts in parallel batches
        for (let batchStart = 1; batchStart <= partCount; batchStart += PARALLEL_PARTS) {
            const batchEnd = Math.min(batchStart + PARALLEL_PARTS - 1, partCount)
            const promises = []

            for (let partNum = batchStart; partNum <= batchEnd; partNum++) {
                const offset = (partNum - 1) * PART_SIZE
                const length = Math.min(PART_SIZE, fileSize - offset)
                promises.push(uploadSinglePart(auth, fileId, filePath, partNum, offset, length, fileSize))
            }

            process.stdout.write(`\r   â¬† Uploading parts ${batchStart}-${batchEnd}/${partCount}...`)
            const results = await Promise.all(promises)

            for (const { partNum, sha1 } of results) {
                partSha1s[partNum - 1] = sha1
                completedParts++
            }

            // Report upload progress to UI (50% â†’ 95%)
            if (jobId) {
                const uploadProgress = Math.round(50 + (completedParts / partCount) * 45)
                updateJob(jobId, { progress: uploadProgress, updatedAt: new Date().toISOString() }).catch(() => { })

                // Check if user cancelled every 2 batches
                if (batchStart % (PARALLEL_PARTS * 2) === 1) {
                    const cancelled = await checkJobCancelled(jobId)
                    if (cancelled) {
                        throw new Error('ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨')
                    }
                }
            }
        }

        console.log(`\n   âœ… All ${partCount} parts uploaded (parallel)`)

        // Step 3: Finish large file
        const finishRes = await fetch(`${auth.apiUrl}/b2api/v2/b2_finish_large_file`, {
            method: 'POST',
            headers: {
                'Authorization': auth.authorizationToken,
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                fileId,
                partSha1Array: partSha1s,
            })
        })
        if (!finishRes.ok) {
            const text = await finishRes.text()
            throw new Error(`B2 finish large file failed: ${text}`)
        }
        return await finishRes.json()
    } catch (err) {
        // Cancel the large file on error
        try {
            await fetch(`${auth.apiUrl}/b2api/v2/b2_cancel_large_file`, {
                method: 'POST',
                headers: {
                    'Authorization': auth.authorizationToken,
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ fileId })
            })
            console.log('   ğŸ—‘ Cancelled incomplete large file upload')
        } catch { }
        throw err
    }
}

async function uploadToB2(filePath, fileName, jobId = null) {
    const auth = await authorizeB2()
    const fileSize = fs.statSync(filePath).size

    const ext = path.extname(fileName).toLowerCase()
    const contentTypes = {
        '.mp4': 'video/mp4', '.webm': 'video/webm', '.avi': 'video/x-msvideo',
        '.mov': 'video/quicktime', '.mkv': 'video/x-matroska',
        '.flv': 'video/x-flv', '.wmv': 'video/x-ms-wmv',
        '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png',
    }
    const contentType = contentTypes[ext] || 'application/octet-stream'
    // If fileName already includes a folder prefix (e.g. "thumbnails/..."), keep folder and add timestamp to basename
    let b2FileName
    if (fileName.includes('/')) {
        const lastSlash = fileName.lastIndexOf('/')
        const folder = fileName.substring(0, lastSlash + 1)
        const base = fileName.substring(lastSlash + 1)
        b2FileName = `${folder}${Date.now()}_${base}`
    } else {
        b2FileName = `videos/${Date.now()}_${fileName}`
    }

    console.log(`   â¬† Uploading to B2: ${fileName} (${(fileSize / 1024 / 1024).toFixed(1)}MB)`)

    // Use large file API for files > 100MB
    if (fileSize > 100 * 1024 * 1024) {
        const result = await uploadLargeFile(auth, filePath, b2FileName, contentType, jobId)
        const b2Url = `/api/b2-proxy?file=${encodeURIComponent(b2FileName)}`
        console.log(`   âœ… B2 upload complete: ${b2FileName}`)
        return b2Url
    }

    // Small file: streaming upload (avoid loading entire file into memory)
    const uploadUrl = await getB2UploadUrl(auth)

    // Compute SHA1 via streaming
    const sha1 = await new Promise((resolve, reject) => {
        const hash = crypto.createHash('sha1')
        const stream = fs.createReadStream(filePath)
        stream.on('data', chunk => hash.update(chunk))
        stream.on('end', () => resolve(hash.digest('hex')))
        stream.on('error', reject)
    })

    // Use streaming body for upload
    const { Readable } = require('stream')
    const fileStream = fs.createReadStream(filePath)

    const uploadRes = await fetch(uploadUrl.uploadUrl, {
        method: 'POST',
        headers: {
            'Authorization': uploadUrl.authorizationToken,
            'X-Bz-File-Name': encodeURIComponent(b2FileName),
            'Content-Type': contentType,
            'Content-Length': fileSize.toString(),
            'X-Bz-Content-Sha1': sha1,
        },
        body: fileStream,
        duplex: 'half',
    })

    if (!uploadRes.ok) {
        const errText = await uploadRes.text()
        throw new Error(`B2 upload failed (${uploadRes.status}): ${errText}`)
    }

    // Report small file upload complete
    if (jobId) {
        updateJob(jobId, { progress: 95, updatedAt: new Date().toISOString() }).catch(() => { })
    }

    const b2Url = `/api/b2-proxy?file=${encodeURIComponent(b2FileName)}`
    console.log(`   âœ… B2 upload complete: ${b2FileName}`)
    return b2Url
}

// ============================================
// Global browser instance
// ============================================
let browser = null
let isLoggedIn = false

async function getBrowser() {
    if (!browser || !browser.connected) {
        console.log('ğŸŒ Launching browser...')
        // Close old crashed browser if exists
        if (browser) {
            try { await browser.close() } catch { }
            browser = null
        }
        browser = await puppeteer.launch({
            headless: 'new',
            args: ['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage', '--disable-gpu'],
        })
        isLoggedIn = false
        console.log('   âœ… Browser launched')
    }
    return browser
}

// ============================================
// Login to skbj.tv
// ============================================
async function loginToSkbj(forceRelogin = false) {
    if (isLoggedIn && !forceRelogin) return
    isLoggedIn = false // Reset before attempting

    const b = await getBrowser()
    const page = await b.newPage()

    try {
        await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36')

        console.log('ğŸ”‘ Logging in to skbj.tv...')
        await page.goto('https://skbj.tv/login', { waitUntil: 'networkidle2', timeout: 60000 })

        // Wait for Cloudflare
        await page.waitForFunction(() => !document.title.includes('Just a moment'), { timeout: 30000 }).catch(() => { })
        await new Promise(r => setTimeout(r, 3000))

        // Find login inputs
        const loginSelectors = ['input[type="email"]', 'input[name="email"]', 'input[name="username"]', 'input[name="login"]', 'input[id="email"]', 'input[placeholder*="ì´ë©”ì¼"]', 'input[placeholder*="email"]']
        const passwordSelectors = ['input[type="password"]', 'input[name="password"]', 'input[id="password"]']

        let emailInput = null
        for (const sel of loginSelectors) {
            emailInput = await page.$(sel)
            if (emailInput) { console.log(`   Found email input: ${sel}`); break }
        }

        let passwordInput = null
        for (const sel of passwordSelectors) {
            passwordInput = await page.$(sel)
            if (passwordInput) { console.log(`   Found password input: ${sel}`); break }
        }

        if (!emailInput || !passwordInput) {
            const debugPath = path.join(TEMP_DIR, 'login_debug.png')
            await page.screenshot({ path: debugPath, fullPage: true })
            await page.close()
            throw new Error('Login form not found. Check worker/temp/login_debug.png')
        }

        await emailInput.click({ clickCount: 3 })
        await emailInput.type(SKBJ_EMAIL, { delay: 50 })
        await passwordInput.click({ clickCount: 3 })
        await passwordInput.type(SKBJ_PASSWORD, { delay: 50 })

        // Submit
        const btn = await page.$('button[type="submit"]')
        if (btn) await btn.click()
        else await passwordInput.press('Enter')

        await page.waitForNavigation({ waitUntil: 'networkidle2', timeout: 15000 }).catch(() => { })
        await new Promise(r => setTimeout(r, 2000))

        if (!page.url().includes('/login')) {
            isLoggedIn = true
            console.log('   âœ… Login successful!')
        } else {
            console.log('   âŒ Login may have failed.')
        }

        await page.close()
    } catch (err) {
        isLoggedIn = false // Ensure flag is reset on failure
        try { await page.close() } catch { }
        throw err
    }
}

// ============================================
// Extract video URL + title + streamer hint
// With overall 120-second timeout safety net
// ============================================
async function extractVideoUrl(pageUrl) {
    // Overall timeout wrapper â€” if extraction takes > 120s, abort entirely
    return Promise.race([
        _extractVideoUrlInner(pageUrl),
        new Promise((_, reject) =>
            setTimeout(() => reject(new Error(`extractVideoUrl timed out after 120s for: ${pageUrl}`)), 120000)
        )
    ])
}

async function _extractVideoUrlInner(pageUrl) {
    console.log(`   [${new Date().toLocaleTimeString()}] ğŸ” extractVideoUrl ì‹œì‘: ${pageUrl}`)
    await loginToSkbj()

    const b = await getBrowser()
    const page = await b.newPage()

    try {
        await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36')

        // Intercept network requests for video URLs
        const videoUrls = []
        await page.setRequestInterception(true)
        page.on('request', (req) => {
            const url = req.url()
            if ((url.includes('.mp4') || url.includes('.m3u8') || url.includes('.webm') ||
                url.includes('/video/') || url.includes('stream')) &&
                !url.includes('.js') && !url.includes('.css')) {
                videoUrls.push(url)
            }
            req.continue()
        })

        console.log(`   [${new Date().toLocaleTimeString()}] ğŸ” Navigating to: ${pageUrl}`)
        await page.goto(pageUrl, { waitUntil: 'networkidle2', timeout: 45000 }).catch(() => {
            console.warn('   âš ï¸ Navigation networkidle2 timed out, continuing with domcontentloaded...')
            return page.goto(pageUrl, { waitUntil: 'domcontentloaded', timeout: 15000 }).catch(() => { })
        })

        // Cloudflare ëŒ€ê¸° â€” ìµœëŒ€ 30ì´ˆ, 2ì´ˆ ê°„ê²© ì¬í™•ì¸
        for (let retry = 0; retry < 15; retry++) {
            const currentTitle = await page.title()
            if (!currentTitle.includes('Just a moment') && !currentTitle.includes('Checking')) break
            console.log(`   â³ Cloudflare ëŒ€ê¸° ì¤‘... (${retry + 1}/15)`)
            await new Promise(r => setTimeout(r, 2000))
        }
        await new Promise(r => setTimeout(r, 3000))

        // ============================================
        // ë‹¤ì¤‘ ì „ëµ ì œëª© ì¶”ì¶œ (Deep Scraping)
        // ============================================
        const pageTitle = await page.evaluate(() => {
            // 1ìˆœìœ„: OG title meta tag
            const ogTitle = document.querySelector('meta[property="og:title"]')?.getAttribute('content')
            if (ogTitle && ogTitle.trim().length > 2) return ogTitle.trim()

            // 2ìˆœìœ„: twitter:title meta tag  
            const twTitle = document.querySelector('meta[name="twitter:title"]')?.getAttribute('content')
            if (twTitle && twTitle.trim().length > 2) return twTitle.trim()

            // 3ìˆœìœ„: h1 íƒœê·¸ (ê°€ì¥ í° ì œëª©)
            const h1 = document.querySelector('h1')?.textContent?.trim()
            if (h1 && h1.length > 2 && h1.length < 200) return h1

            // 4ìˆœìœ„: ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ ê·¼ì²˜ ì œëª© ì˜ì—­
            const videoTitleSelectors = [
                '.video-title', '.title', '[class*="title"]',
                '.video-info h2', '.video-details h2',
                '.content-title', '.post-title',
            ]
            for (const sel of videoTitleSelectors) {
                const el = document.querySelector(sel)
                const text = el?.textContent?.trim()
                if (text && text.length > 2 && text.length < 200) return text
            }

            // 5ìˆœìœ„: h2 íƒœê·¸
            const h2 = document.querySelector('h2')?.textContent?.trim()
            if (h2 && h2.length > 2 && h2.length < 200) return h2

            // 6ìˆœìœ„: document.title (ì‚¬ì´íŠ¸ëª… ì œê±°)
            const docTitle = document.title
            if (docTitle && !docTitle.includes('Just a moment') && docTitle.length > 2) {
                // " - site.com" ë˜ëŠ” " | site" íŒ¨í„´ ì œê±°
                return docTitle.replace(/\s*[-|]\s*[^-|]*$/, '').trim()
            }

            return ''
        })
        console.log(`   ğŸ“ ì¶”ì¶œëœ ì œëª©: "${pageTitle || '(ì—†ìŒ)'}" `)

        // ============================================
        // ìŠ¤íŠ¸ë¦¬ë¨¸ íŒíŠ¸ ì¶”ì¶œ (í˜ì´ì§€ì—ì„œ)
        // ============================================
        const streamerHint = await page.evaluate(() => {
            const hints = []

            // ì±„ë„/ì—…ë¡œë” ê´€ë ¨ ìš”ì†Œ íƒìƒ‰
            const selectors = [
                '.channel-name', '.uploader', '.uploader-name',
                '[class*="author"]', '[class*="channel"]', '[class*="creator"]',
                '[class*="username"]', '[class*="user-name"]',
                '.video-info .name', '.video-uploader',
                // í”„ë¡œí•„ ë§í¬ í…ìŠ¤íŠ¸
            ]
            for (const sel of selectors) {
                const el = document.querySelector(sel)
                const text = el?.textContent?.trim()
                if (text && text.length > 1 && text.length < 50) {
                    hints.push(text)
                }
            }

            // í”„ë¡œí•„/ì±„ë„ ë§í¬ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            const profileLinks = document.querySelectorAll(
                'a[href*="/user/"], a[href*="/channel/"], a[href*="/profile/"], a[href*="/model/"], a[href*="/actress/"], a[href*="/pornstar/"]'
            )
            profileLinks.forEach(a => {
                const text = a.textContent?.trim()
                if (text && text.length > 1 && text.length < 50) hints.push(text)
                // hrefì—ì„œë„ ì´ë¦„ ì¶”ì¶œ
                const href = a.getAttribute('href') || ''
                const nameFromHref = href.split('/').filter(Boolean).pop()
                if (nameFromHref && nameFromHref.length > 1) hints.push(nameFromHref)
            })

            // OG ë˜ëŠ” metaì—ì„œ ì¶”ì¶œ
            const ogAuthor = document.querySelector('meta[name="author"]')?.getAttribute('content')
            if (ogAuthor) hints.push(ogAuthor)

            // íƒœê·¸/ì¹´í…Œê³ ë¦¬ì—ì„œ ì¶”ì¶œ
            const tagElements = document.querySelectorAll('.tag, [class*="tag"], .category a, [class*="categor"] a')
            tagElements.forEach(t => {
                const text = t.textContent?.trim()
                if (text && text.length > 1 && text.length < 30) hints.push(text)
            })

            return [...new Set(hints)]
        })
        if (streamerHint.length > 0) {
            console.log(`   ğŸ‘¤ ìŠ¤íŠ¸ë¦¬ë¨¸ íŒíŠ¸: [${streamerHint.slice(0, 5).join(', ')}]`)
        }

        // Click play button to trigger video URL loading
        const playSelectors = ['button.play-btn', 'button.vjs-big-play-button', '.video-play-button', '.play-button', 'button[aria-label="Play"]', '.vjs-poster', 'video', '.plyr__control--overlaid', '[data-plyr="play"]']
        for (const sel of playSelectors) {
            try {
                const el = await page.$(sel)
                if (el) { await el.click(); console.log(`   â–¶ Clicked: ${sel}`); break }
            } catch { }
        }

        await new Promise(r => setTimeout(r, 5000))

        // Extract from DOM
        const videoSrc = await page.evaluate(() => {
            const sources = []
            document.querySelectorAll('video').forEach(v => {
                if (v.src) sources.push(v.src)
                if (v.currentSrc) sources.push(v.currentSrc)
                v.querySelectorAll('source').forEach(s => { if (s.src) sources.push(s.src) })
            })
            return sources
        })

        // Extract from HTML source
        const html = await page.content()
        const htmlUrls = []
        const patterns = [/https?:\/\/[^"'\s<>]+\.mp4[^"'\s<>]*/gi, /https?:\/\/[^"'\s<>]+\.m3u8[^"'\s<>]*/gi]
        for (const p of patterns) {
            for (const m of html.matchAll(p)) htmlUrls.push(m[0])
        }

        // Get cookies
        const cookies = await page.cookies()
        const cookieString = cookies.map(c => `${c.name}=${c.value}`).join('; ')

        const allUrls = [...new Set([...videoUrls, ...videoSrc, ...htmlUrls])].filter(u => u.startsWith('http'))
        const mp4s = allUrls.filter(u => u.includes('.mp4'))
        const m3u8s = allUrls.filter(u => u.includes('.m3u8'))
        const bestUrl = mp4s[0] || m3u8s[0] || allUrls[0]

        if (allUrls.length > 0) {
            console.log(`   Found ${allUrls.length} video URL(s):`)
            allUrls.slice(0, 3).forEach(u => console.log(`     - ${u.substring(0, 100)}...`))
        }

        if (!bestUrl) {
            await page.screenshot({ path: path.join(TEMP_DIR, 'video_debug.png'), fullPage: true })
            fs.writeFileSync(path.join(TEMP_DIR, 'video_debug.html'), html)
        }

        await page.close()
        return {
            videoUrl: bestUrl || null,
            pageTitle: pageTitle || '',
            streamerHint: streamerHint || [],
            cookieString,
        }
    } catch (err) {
        console.error(`   [${new Date().toLocaleTimeString()}] âŒ extractVideoUrl ì‹¤íŒ¨:`, err.message)
        try { await page.close() } catch { }
        // If login might have expired, force re-login next time
        if (err.message?.includes('Login') || err.message?.includes('timeout')) {
            isLoggedIn = false
        }
        throw err
    }
}

// ============================================
// API Request (for non-queue endpoints only, e.g. add-video)
// ============================================
async function apiRequest(endpoint, method = 'GET', body = null, timeoutMs = 15000) {
    const url = `${SITE_URL}${endpoint}`
    const controller = new AbortController()
    const timer = setTimeout(() => controller.abort(), timeoutMs)
    try {
        const options = {
            method,
            headers: { 'Content-Type': 'application/json', 'x-admin-token': ADMIN_TOKEN },
            signal: controller.signal,
        }
        if (body) options.body = JSON.stringify(body)
        const res = await fetch(url, options)
        if (!res.ok) {
            const text = await res.text()
            throw new Error(`API ${method} ${endpoint} failed (${res.status}): ${text}`)
        }
        return res.json()
    } catch (err) {
        if (err.name === 'AbortError') {
            throw new Error(`API ${method} ${endpoint} timed out after ${timeoutMs}ms`)
        }
        throw err
    } finally {
        clearTimeout(timer)
    }
}

// checkJobCancelled â€” imported from firebase-direct.js (REST API)

// Get streamers from Firestore directly (REST API)
async function getStreamersFromDB() {
    try {
        return await getStreamers()
    } catch (e) {
        console.warn('   âš ï¸ ìŠ¤íŠ¸ë¦¬ë¨¸ DB ì¡°íšŒ ì˜¤ë¥˜:', e.message)
        return []
    }
}

// ============================================
// Download file with cookies
// ============================================
function downloadFile(url, destPath, cookies = '', onProgress = null) {
    return new Promise((resolve, reject) => {
        const file = fs.createWriteStream(destPath)
        const protocol = url.startsWith('https') ? https : http
        const urlObj = new URL(url)

        const headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            'Referer': 'https://skbj.tv/', 'Origin': 'https://skbj.tv',
        }
        if (cookies) headers['Cookie'] = cookies

        const request = protocol.request({
            hostname: urlObj.hostname,
            port: urlObj.port || (url.startsWith('https') ? 443 : 80),
            path: urlObj.pathname + urlObj.search,
            method: 'GET', headers,
        }, (response) => {
            if ([301, 302, 307, 308].includes(response.statusCode)) {
                file.close()
                if (fs.existsSync(destPath)) fs.unlinkSync(destPath)
                const redir = response.headers.location
                const fullUrl = redir.startsWith('http') ? redir : new URL(redir, url).href
                return downloadFile(fullUrl, destPath, cookies).then(resolve).catch(reject)
            }
            if (response.statusCode !== 200) {
                file.close()
                if (fs.existsSync(destPath)) fs.unlinkSync(destPath)
                return reject(new Error(`Download failed: HTTP ${response.statusCode}`))
            }

            const totalSize = parseInt(response.headers['content-length'] || '0')
            let downloaded = 0
            let lastReportedPct = 0
            response.on('data', (chunk) => {
                downloaded += chunk.length
                if (totalSize > 0) {
                    const pct = Math.round((downloaded / totalSize) * 100)
                    process.stdout.write(`\r   â¬‡ ë‹¤ìš´ë¡œë“œ ì¤‘: ${pct}% (${(downloaded / 1024 / 1024).toFixed(1)}MB / ${(totalSize / 1024 / 1024).toFixed(1)}MB)`)
                    // Report download progress to UI (10% â†’ 50%) every 10%
                    if (onProgress && pct >= lastReportedPct + 10) {
                        lastReportedPct = pct
                        const uiProgress = Math.round(10 + (pct / 100) * 40)
                        onProgress(uiProgress)
                    }
                } else {
                    process.stdout.write(`\r   â¬‡ ë‹¤ìš´ë¡œë“œ ì¤‘: ${(downloaded / 1024 / 1024).toFixed(1)}MB`)
                }
            })
            response.pipe(file)
            file.on('finish', () => {
                file.close()
                console.log(`\n   âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: ${(downloaded / 1024 / 1024).toFixed(1)}MB`)
                resolve(destPath)
            })
        })

        request.on('error', (err) => {
            file.close()
            if (fs.existsSync(destPath)) fs.unlinkSync(destPath)
            reject(err)
        })
        request.setTimeout(3600000, () => {
            request.destroy()
            if (fs.existsSync(destPath)) fs.unlinkSync(destPath)
            reject(new Error('ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ (60ë¶„)'))
        })
        request.end()
    })
}

// ============================================
// Detect video codec using ffprobe
// ============================================
function detectCodec(filePath) {
    try {
        const codec = execSync(
            `ffprobe -v error -analyzeduration 100M -probesize 100M -select_streams v:0 -show_entries stream=codec_name -of default=noprint_wrappers=1:nokey=1 "${filePath}"`,
            { encoding: 'utf8', timeout: 30000 }
        ).trim().toLowerCase()
        return codec
    } catch (e) {
        console.warn(`   âš ï¸ ì½”ë± ê°ì§€ ì‹¤íŒ¨:`, e.message)
        return 'unknown'
    }
}

// ============================================
// Transcode HEVC to H.264 for browser compatibility
// ============================================
function transcodeToH264(inputPath, outputPath, jobId = null) {
    console.log(`   ğŸ”„ HEVC â†’ H.264 íŠ¸ëœìŠ¤ì½”ë”© ì‹œì‘...`)
    try {
        execSync(
            `ffmpeg -y -i "${inputPath}" -c:v libx264 -crf 23 -preset medium -c:a aac -movflags +faststart "${outputPath}"`,
            { timeout: 7200000, stdio: 'pipe' } // 2 hour timeout for long videos
        )
        const inputSize = (fs.statSync(inputPath).size / 1024 / 1024).toFixed(1)
        const outputSize = (fs.statSync(outputPath).size / 1024 / 1024).toFixed(1)
        console.log(`   âœ… íŠ¸ëœìŠ¤ì½”ë”© ì™„ë£Œ: ${inputSize}MB â†’ ${outputSize}MB`)
        return true
    } catch (e) {
        console.error(`   âŒ íŠ¸ëœìŠ¤ì½”ë”© ì‹¤íŒ¨:`, e.message)
        return false
    }
}

// ============================================
// Process a single job
// ============================================
async function processJob(job) {
    console.log(`\n${'â•'.repeat(50)}`)
    console.log(`ğŸ“¥ ì‘ì—… ì²˜ë¦¬ ì¤‘: ${job.title || job.sourceUrl}`)
    console.log(`   ID: ${job.id}`)
    console.log(`   URL: ${job.sourceUrl}`)
    console.log(`${'â”€'.repeat(50)}`)

    const tempFile = path.join(TEMP_DIR, `dl_${Date.now()}_${crypto.randomBytes(4).toString('hex')}.mp4`)
    const transcodedFile = tempFile.replace('.mp4', '_h264.mp4')
    let activeFile = tempFile // Points to the file we'll actually upload (original or transcoded)

    try {
        console.log(`   [${new Date().toLocaleTimeString()}] â–¶ ì‘ì—… ì‹œì‘`)
        // Progress 5 update â€” non-blocking, don't fail job if this fails
        updateJob(job.id, { progress: 5, updatedAt: new Date().toISOString() }).catch(e => {
            console.warn(`   âš ï¸ progress 5 ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ):`, e.message)
        })

        const isLocalFile = job.sourceUrl.startsWith('local://')
        let title = ''
        let rawSlug = ''
        let fileName = 'video.mp4'
        let extractedTitle = ''
        let extractedDate = ''
        let remainder = ''

        if (isLocalFile) {
            // ============================================
            // ë¡œì»¬ íŒŒì¼ ëª¨ë“œ: í´ë” ê°ì‹œì—ì„œ ì¶”ê°€ëœ job
            // ============================================
            const localPath = job.sourceUrl.replace('local://', '')
            console.log(`   ğŸ“‚ ë¡œì»¬ íŒŒì¼ ëª¨ë“œ: ${localPath}`)

            if (!fs.existsSync(localPath)) {
                throw new Error(`ë¡œì»¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${localPath}`)
            }

            // Copy local file to temp (don't move original yet)
            fileName = path.basename(localPath)
            fs.copyFileSync(localPath, tempFile)
            const fileSize = (fs.statSync(tempFile).size / 1024 / 1024).toFixed(1)
            console.log(`   âœ… ë¡œì»¬ íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: ${fileSize}MB`)

            // Derive title from filename
            rawSlug = path.basename(localPath, path.extname(localPath))
            // Extract date (YYYY_MM_DD) from filename
            extractedDate = ''
            remainder = rawSlug
            // Try YYYYMMDD (8 digits at start or after separator)
            const dateMatch8 = rawSlug.match(/(\d{4})(\d{2})(\d{2})/)
            if (dateMatch8) {
                extractedDate = `${dateMatch8[1]}_${dateMatch8[2]}_${dateMatch8[3]}`
                remainder = rawSlug.replace(dateMatch8[0], '')
            } else {
                // Try YYYY-MM-DD or YYYY_MM_DD
                const dateMatchSep = rawSlug.match(/(\d{4})[-_](\d{2})[-_](\d{2})/)
                if (dateMatchSep) {
                    extractedDate = `${dateMatchSep[1]}_${dateMatchSep[2]}_${dateMatchSep[3]}`
                    remainder = rawSlug.replace(dateMatchSep[0], '')
                }
            }
            // Clean remainder: replace separators with spaces, trim
            remainder = remainder.replace(/[_\-]+/g, ' ').trim()
            title = job.title || remainder || 'Untitled'
            console.log(`   ğŸ“‹ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ â€” ë‚ ì§œ: "${extractedDate}", ë‚˜ë¨¸ì§€: "${remainder}"`)

            await updateJob(job.id, {
                progress: 40,
                title: title,
                updatedAt: new Date().toISOString(),
            })
        } else {
            // ============================================
            // URL ëª¨ë“œ: ê¸°ì¡´ ë¡œì§
            // ============================================
            // Extract video URL
            console.log('   ğŸ” ì˜ìƒ URL ì¶”ì¶œ ì¤‘...')
            const result = await extractVideoUrl(job.sourceUrl)
            if (!result.videoUrl) throw new Error('ì˜ìƒ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. worker/temp/video_debug.png í™•ì¸')

            console.log(`   ğŸ“ ì˜ìƒ URL: ${result.videoUrl.substring(0, 80)}...`)
            // ============================================
            // ì œëª© ê²°ì •: ë‹¤ì¤‘ ì†ŒìŠ¤ + slug ì •ë¦¬ í´ë°±
            // ============================================
            extractedTitle = result.pageTitle || ''
            const urlPath = new URL(job.sourceUrl).pathname
            rawSlug = (urlPath.split('/').pop() || '').replace(/\.[^.]+$/, '')
            // URL slugì—ì„œ ë‚ ì§œ ì¶”ì¶œ ë° ë‚˜ë¨¸ì§€ ë¶„ë¦¬
            extractedDate = ''
            let urlRemainder = rawSlug
            const urlDateMatch8 = rawSlug.match(/(\d{4})(\d{2})(\d{2})/)
            if (urlDateMatch8) {
                extractedDate = `${urlDateMatch8[1]}_${urlDateMatch8[2]}_${urlDateMatch8[3]}`
                urlRemainder = rawSlug.replace(urlDateMatch8[0], '')
            } else {
                const urlDateMatchSep = rawSlug.match(/(\d{4})[-_](\d{2})[-_](\d{2})/)
                if (urlDateMatchSep) {
                    extractedDate = `${urlDateMatchSep[1]}_${urlDateMatchSep[2]}_${urlDateMatchSep[3]}`
                    urlRemainder = rawSlug.replace(urlDateMatchSep[0], '')
                }
            }
            const cleanedSlug = urlRemainder
                .replace(/[_\-]+/g, ' ')
                .replace(/\b\w/g, c => c.toUpperCase())
                .trim()
            remainder = cleanedSlug

            if (job.titleSource === 'fileName') {
                title = cleanedSlug || extractedTitle || job.title || 'Untitled'
            } else {
                title = job.title || extractedTitle || cleanedSlug || 'Untitled'
            }
            console.log(`   ğŸ“‹ ìµœì¢… ì œëª© ê²°ì •: "${title}"`)
            console.log(`     â”œ ìˆ˜ë™ ì…ë ¥: "${job.title || '(ì—†ìŒ)'}"`)
            console.log(`     â”œ í˜ì´ì§€ ì¶”ì¶œ: "${extractedTitle || '(ì—†ìŒ)'}"`)
            console.log(`     â”” URL slug: "${cleanedSlug || '(ì—†ìŒ)'}"`)

            await updateJob(job.id, {
                progress: 10,
                title: title,
                updatedAt: new Date().toISOString(),
            })

            // Download
            console.log('   â¬‡ ë‹¤ìš´ë¡œë“œ ì‹œì‘...')
            await downloadFile(result.videoUrl, tempFile, result.cookieString, (progress) => {
                updateJob(job.id, { progress, updatedAt: new Date().toISOString() }).catch(() => { })
            })

            try {
                const baseName = path.basename(new URL(result.videoUrl).pathname)
                if (baseName && path.extname(baseName)) fileName = baseName
            } catch { }
            if (!path.extname(fileName)) fileName += '.mp4'
        }

        // ============================================
        // HEVC Detection & Auto-Transcoding
        // ============================================
        const codec = detectCodec(tempFile)
        console.log(`   ğŸ¬ ê°ì§€ëœ ì½”ë±: ${codec}`)

        if (codec === 'hevc' || codec === 'h265') {
            console.log(`   âš ï¸ HEVC ì½”ë± ê°ì§€ â†’ H.264ë¡œ íŠ¸ëœìŠ¤ì½”ë”© í•„ìš”`)
            await updateJob(job.id, {
                progress: 45,
                updatedAt: new Date().toISOString(),
            })

            const success = transcodeToH264(tempFile, transcodedFile, job.id)
            if (success && fs.existsSync(transcodedFile) && fs.statSync(transcodedFile).size > 0) {
                activeFile = transcodedFile
                console.log(`   âœ… H.264 ë³€í™˜ ì™„ë£Œ, ë³€í™˜ëœ íŒŒì¼ ì‚¬ìš©`)
            } else {
                console.warn(`   âš ï¸ íŠ¸ëœìŠ¤ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì—…ë¡œë“œ`)
                activeFile = tempFile
            }
        }

        await updateJob(job.id, {
            progress: 50,
            title: title,
            updatedAt: new Date().toISOString(),
        })

        // B2ì— ì§ì ‘ ì—…ë¡œë“œ
        const b2Url = await uploadToB2(activeFile, fileName, job.id)

        const finalTitle = title

        await updateJob(job.id, {
            status: 'done', progress: 100, b2Url,
            title: finalTitle,
            updatedAt: new Date().toISOString(),
        })

        // ============================================
        // Register video in the site database
        // ============================================
        try {
            // Determine streamer: prefer job-provided values, fallback to smart matching
            let streamerName = job.streamerName || null
            let streamerId = job.streamerId || null
            let streamerKoreanName = ''

            // Extract slug from URL for matching
            const slug = rawSlug.toLowerCase()

            if (!streamerName) {
                try {
                    const allStreamers = await getStreamersFromDB()
                    if (allStreamers.length > 0) {
                        // Sort by name length (longest first) to match most specific name
                        const sortedStreamers = allStreamers.sort((a, b) =>
                            (b.name?.length || 0) - (a.name?.length || 0)
                        )

                        let matched = null

                        // 1ë‹¨ê³„: streamerHint (í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ê²°ê³¼) ë§¤ì¹­ â€” URL ëª¨ë“œì—ì„œë§Œ ê°€ëŠ¥
                        const streamerHints = (!isLocalFile && typeof result !== 'undefined' && result.streamerHint) ? result.streamerHint : []
                        if (streamerHints.length > 0) {
                            for (const hint of streamerHints) {
                                const hintLower = hint.toLowerCase()
                                matched = sortedStreamers.find(s =>
                                    hintLower.includes(s.name?.toLowerCase()) ||
                                    hintLower.includes(s.id?.toLowerCase()) ||
                                    (s.koreanName && hintLower.includes(s.koreanName.toLowerCase())) ||
                                    s.name?.toLowerCase().includes(hintLower) ||
                                    s.id?.toLowerCase().includes(hintLower) ||
                                    (s.koreanName && s.koreanName.toLowerCase().includes(hintLower))
                                )
                                if (matched) {
                                    console.log(`   ğŸ‘¤ í˜ì´ì§€ íŒíŠ¸ì—ì„œ ìŠ¤íŠ¸ë¦¬ë¨¸ ë§¤ì¹­: "${hint}" â†’ ${matched.name} (${matched.koreanName || ''})`)
                                    break
                                }
                            }
                        }

                        // 2ë‹¨ê³„: ì œëª©ì—ì„œ ìŠ¤íŠ¸ë¦¬ë¨¸ ë§¤ì¹­
                        if (!matched && extractedTitle) {
                            const titleLower = extractedTitle.toLowerCase()
                            matched = sortedStreamers.find(s =>
                                titleLower.includes(s.name?.toLowerCase()) ||
                                (s.koreanName && titleLower.includes(s.koreanName.toLowerCase()))
                            )
                            if (matched) {
                                console.log(`   ğŸ‘¤ ì œëª©ì—ì„œ ìŠ¤íŠ¸ë¦¬ë¨¸ ë§¤ì¹­: "${extractedTitle}" â†’ ${matched.name}`)
                            }
                        }

                        // 3ë‹¨ê³„: URL slugì—ì„œ ë§¤ì¹­ (ê¸°ì¡´ ë¡œì§)
                        if (!matched) {
                            matched = sortedStreamers.find(s =>
                                slug.includes(s.id?.toLowerCase()) ||
                                slug.includes(s.name?.toLowerCase()) ||
                                (s.koreanName && slug.includes(s.koreanName.toLowerCase()))
                            )
                            if (matched) {
                                console.log(`   ğŸ‘¤ URL slugì—ì„œ ìŠ¤íŠ¸ë¦¬ë¨¸ ë§¤ì¹­: ${matched.name} (${matched.koreanName || ''})`)
                            }
                        }

                        if (matched) {
                            streamerId = matched.id
                            streamerName = matched.name
                            streamerKoreanName = matched.koreanName || ''
                        }
                    }
                } catch { }

                // Fallback: URL slugì—ì„œ ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
                if (!streamerName) {
                    const parts = slug.split('-').filter(p => p.length > 1)
                    streamerName = parts[parts.length - 1] || 'unknown'
                    console.log(`   ğŸ‘¤ URL ëë¶€ë¶„ì—ì„œ ìŠ¤íŠ¸ë¦¬ë¨¸ ì¶”ì¶œ(í´ë°±): ${streamerName}`)
                }
            }

            if (!streamerId) streamerId = streamerName

            // Extract real video duration AND dimensions using ffprobe (use activeFile for accurate results)
            let duration = '0:00'
            let videoOrientation = 'horizontal'
            try {
                const durationOutput = execSync(
                    `ffprobe -v error -analyzeduration 100M -probesize 100M -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${activeFile}"`,
                    { encoding: 'utf8', timeout: 30000 }
                ).trim()
                const totalSeconds = Math.round(parseFloat(durationOutput))
                if (totalSeconds > 0) {
                    const hours = Math.floor(totalSeconds / 3600)
                    const minutes = Math.floor((totalSeconds % 3600) / 60)
                    const seconds = totalSeconds % 60
                    duration = hours > 0
                        ? `${hours}:${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`
                        : `${minutes}:${String(seconds).padStart(2, '0')}`
                    console.log(`   â±ï¸ ì˜ìƒ ê¸¸ì´: ${duration}`)
                }
            } catch (e) {
                console.warn(`   âš ï¸ ffprobe ì‹¤íŒ¨:`, e.message)
            }

            // Auto-detect orientation via ffprobe (width vs height)
            try {
                const dimOutput = execSync(
                    `ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=p=0 "${activeFile}"`,
                    { encoding: 'utf8', timeout: 15000 }
                ).trim()
                const [w, h] = dimOutput.split(',').map(Number)
                if (w > 0 && h > 0) {
                    videoOrientation = h > w ? 'vertical' : 'horizontal'
                    console.log(`   ğŸ“ ì˜ìƒ ë°©í–¥: ${w}x${h} â†’ ${videoOrientation}`)
                }
            } catch (e) {
                console.warn(`   âš ï¸ ì˜ìƒ ë°©í–¥ ê°ì§€ ì‹¤íŒ¨:`, e.message)
            }

            // Generate thumbnail using ffmpeg (capture at 5 seconds, use activeFile)
            let thumbnailUrl = undefined
            const thumbFile = activeFile.replace(/\.[^.]+$/, '_thumb.jpg')
            try {
                execSync(
                    `ffmpeg -y -analyzeduration 100M -probesize 100M -i "${activeFile}" -ss 5 -vframes 1 -q:v 2 -vf "scale=640:-1" "${thumbFile}"`,
                    { encoding: 'utf8', timeout: 60000, stdio: 'pipe' }
                )
                if (fs.existsSync(thumbFile) && fs.statSync(thumbFile).size > 0) {
                    console.log(`   ğŸ–¼ï¸ ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ`)
                    const thumbB2Name = `thumbnails/${path.basename(fileName, path.extname(fileName))}.jpg`
                    thumbnailUrl = await uploadToB2(thumbFile, thumbB2Name)
                    console.log(`   ğŸ–¼ï¸ ì¸ë„¤ì¼ ì—…ë¡œë“œ ì™„ë£Œ: ${thumbB2Name}`)
                }
            } catch (e) {
                console.warn(`   âš ï¸ ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨:`, e.message)
            } finally {
                if (fs.existsSync(thumbFile)) fs.unlinkSync(thumbFile)
            }

            // Generate 5 preview frames for hover preview (use activeFile)
            const previewUrls = []
            try {
                const totalSeconds = Math.round(parseFloat(
                    execSync(`ffprobe -v error -analyzeduration 100M -probesize 100M -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${activeFile}"`, { encoding: 'utf8', timeout: 15000 }).trim()
                ) || 0)
                if (totalSeconds > 2) {
                    console.log(`   ğŸï¸ ë¯¸ë¦¬ë³´ê¸° í”„ë ˆì„ 5ì¥ ì¶”ì¶œ ì¤‘...`)
                    const frameCount = 5
                    // Evenly spaced points (avoid first/last 10%)
                    const start = Math.max(1, Math.floor(totalSeconds * 0.1))
                    const end = Math.floor(totalSeconds * 0.9)
                    const step = Math.max(1, Math.floor((end - start) / (frameCount - 1)))

                    for (let i = 0; i < frameCount; i++) {
                        const seekTime = Math.min(start + step * i, end)
                        const previewFile = activeFile.replace(/\.[^.]+$/, `_preview${i}.jpg`)
                        try {
                            execSync(
                                `ffmpeg -y -analyzeduration 100M -probesize 100M -ss ${seekTime} -i "${activeFile}" -vframes 1 -q:v 3 -vf "scale=480:-1" "${previewFile}"`,
                                { encoding: 'utf8', timeout: 30000, stdio: 'pipe' }
                            )
                            if (fs.existsSync(previewFile) && fs.statSync(previewFile).size > 0) {
                                const pvB2Name = `previews/${path.basename(fileName, path.extname(fileName))}_${i}.jpg`
                                const pvUrl = await uploadToB2(previewFile, pvB2Name)
                                previewUrls.push(pvUrl)
                            }
                        } catch (e) {
                            console.warn(`   âš ï¸ í”„ë ˆì„ ${i + 1} ì¶”ì¶œ ì‹¤íŒ¨:`, e.message)
                        } finally {
                            if (fs.existsSync(previewFile)) fs.unlinkSync(previewFile)
                        }
                    }
                    console.log(`   ğŸï¸ ë¯¸ë¦¬ë³´ê¸° ${previewUrls.length}ì¥ ì—…ë¡œë“œ ì™„ë£Œ`)
                }
            } catch (e) {
                console.warn(`   âš ï¸ ë¯¸ë¦¬ë³´ê¸° í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨:`, e.message)
            }

            // Find or match streamer in database (secondary check for job-provided streamers)
            if (job.streamerName || job.streamerId) {
                try {
                    const allStreamers = await getStreamersFromDB()
                    if (allStreamers.length > 0) {
                        const found = allStreamers.find(s =>
                            s.id === streamerId ||
                            s.name === streamerName ||
                            s.id === streamerName ||
                            (s.koreanName && s.koreanName === streamerName)
                        )
                        if (found) {
                            streamerId = found.id
                            if (!job.streamerName) streamerName = found.name
                            console.log(`   ğŸ‘¤ ìŠ¤íŠ¸ë¦¬ë¨¸ DB ë§¤ì¹­: ${found.name} (${found.koreanName || ''}) â†’ id: ${found.id}`)
                        } else {
                            console.warn(`   âš ï¸ ìŠ¤íŠ¸ë¦¬ë¨¸ "${streamerName}" DBì— ì—†ìŒ â†’ streamerId: "${streamerId}"`)
                        }
                    }
                } catch { }
            }

            const gradients = [
                'from-pink-700 to-purple-700', 'from-blue-700 to-indigo-700',
                'from-cyan-700 to-teal-700', 'from-amber-700 to-orange-700',
                'from-rose-700 to-pink-700', 'from-violet-700 to-purple-700',
            ]
            const gradient = gradients[Math.floor(Math.random() * gradients.length)]

            const video = {
                title: (() => {
                    // Construct title: YYYY_MM_DD_í•œê¸€ë‹‰_ì˜ì–´ID_ë‚˜ë¨¸ì§€ (skip empty parts)
                    const parts = []
                    if (typeof extractedDate !== 'undefined' && extractedDate) parts.push(extractedDate)
                    if (streamerKoreanName) parts.push(streamerKoreanName)
                    if (streamerName && streamerName !== streamerKoreanName) parts.push(streamerName)
                    // Add remainder (cleaned from date/streamer info)
                    let rem = remainder || ''
                    // Remove streamer name/id/korean from remainder to avoid duplication
                    const escRx = s => s.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')
                    if (streamerName) rem = rem.replace(new RegExp(escRx(streamerName), 'gi'), '').trim()
                    if (streamerKoreanName) rem = rem.replace(new RegExp(escRx(streamerKoreanName), 'gi'), '').trim()
                    if (streamerId && streamerId !== streamerName) rem = rem.replace(new RegExp(escRx(streamerId), 'gi'), '').trim()
                    rem = rem.replace(/^[\s_-]+|[\s_-]+$/g, '').trim()
                    if (rem) parts.push(rem)
                    const constructed = parts.join('_')
                    console.log(`   ğŸ“ ìµœì¢… ì œëª© ì¡°í•©: "${constructed}"`)
                    return constructed || title || 'Untitled'
                })(),
                streamerId,
                streamerName,
                views: 0,
                likes: 0,
                duration,
                isVip: true,
                minStreamingLevel: 'vip',
                minDownloadLevel: 'vip',
                gradient,
                uploadedAt: new Date().toISOString(),
                videoUrl: b2Url,
                thumbnailUrl: thumbnailUrl || undefined,
                previewUrls: previewUrls.length > 0 ? previewUrls : undefined,
                tags: [],
                orientation: videoOrientation,
            }

            // Register video directly in Firestore (REST API)
            const existingStreamer = await getStreamer(streamerId)
            if (!existingStreamer) {
                // Create streamer doc if doesn't exist
                await setDocument('streamers', streamerId, {
                    id: streamerId,
                    name: streamerName || streamerId,
                    videoCount: 0,
                    createdAt: new Date().toISOString(),
                })
            }

            const videoId = `vid_${Date.now()}_${crypto.randomBytes(3).toString('hex')}`
            await addVideo(streamerId, videoId, video)

            // Increment video count
            try {
                const currentData = await getStreamer(streamerId)
                await updateStreamer(streamerId, {
                    videoCount: (currentData?.videoCount || 0) + 1,
                    updatedAt: new Date().toISOString(),
                })
            } catch { }

            console.log(`   ğŸ“º DBì— ì˜ìƒ ë“±ë¡ ì™„ë£Œ: "${video.title}" (${duration})`)
        } catch (regError) {
            console.warn(`   âš ï¸ DB ë“±ë¡ ì˜¤ë¥˜:`, regError.message)
            // Don't fail the job - the video is already uploaded to B2
        }

        console.log(`   ğŸ‰ ì‘ì—… ì™„ë£Œ!`)
    } catch (error) {
        console.error(`   âŒ ì‘ì—… ì‹¤íŒ¨:`, error.message)
        await updateJob(job.id, {
            status: 'failed',
            error: error.message?.substring(0, 500) || 'Unknown error',
            updatedAt: new Date().toISOString(),
        }).catch(e => console.error('ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:', e))
    } finally {
        // Clean up both original and transcoded files
        if (fs.existsSync(tempFile)) fs.unlinkSync(tempFile)
        if (fs.existsSync(transcodedFile)) fs.unlinkSync(transcodedFile)

        // Move processed local file to done/ folder
        if (job.sourceUrl.startsWith('local://')) {
            const localPath = job.sourceUrl.replace('local://', '')
            if (fs.existsSync(localPath)) {
                try {
                    const doneDir = path.join(path.dirname(localPath), 'done')
                    if (!fs.existsSync(doneDir)) fs.mkdirSync(doneDir, { recursive: true })
                    const donePath = path.join(doneDir, path.basename(localPath))
                    fs.renameSync(localPath, donePath)
                    console.log(`   ğŸ“ ì›ë³¸ íŒŒì¼ ì´ë™: done/${path.basename(localPath)}`)
                } catch (e) {
                    console.warn(`   âš ï¸ ì›ë³¸ íŒŒì¼ ì´ë™ ì‹¤íŒ¨:`, e.message)
                }
            }
        }
    }
}

// ============================================
// Main polling loop (with crash recovery)
// ============================================
let consecutiveErrors = 0
const MAX_CONSECUTIVE_ERRORS = 5

// Track active concurrent jobs
const activeJobs = new Map() // jobId -> Promise

async function pollLoop() {
    console.log(`ğŸ”„ ì‘ì—… ëŒ€ê¸° ì¤‘... (${POLL_INTERVAL_MS / 1000}ì´ˆ ê°„ê²©, ë™ì‹œ ${MAX_CONCURRENT_JOBS}ê°œ)`)

    try {
        await loginToSkbj()
        console.log('âœ… ì´ˆê¸° ë¡œê·¸ì¸ ì™„ë£Œ')
    } catch (err) {
        console.error('âš ï¸ ì´ˆê¸° ë¡œê·¸ì¸ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰):', err.message)
    }

    while (true) {
        try {
            // Clean up completed jobs from tracking map
            for (const [id, promise] of activeJobs.entries()) {
                // Check if promise is settled by racing with an instant resolve
                const settled = await Promise.race([
                    promise.then(() => true, () => true),
                    Promise.resolve(false)
                ])
                if (settled) activeJobs.delete(id)
            }

            // Claim jobs up to concurrency limit
            if (activeJobs.size < MAX_CONCURRENT_JOBS) {
                const job = await claimJob(WORKER_ID)
                if (job) {
                    consecutiveErrors = 0
                    const slotNum = activeJobs.size + 1
                    console.log(`\n[${new Date().toLocaleTimeString()}] ğŸ“¦ ì‘ì—… ìˆ˜ì‹  [${slotNum}/${MAX_CONCURRENT_JOBS}]: ${job.sourceUrl}`)

                    // Start job processing but don't await â€” run concurrently
                    const jobPromise = processJob(job).catch(err => {
                        console.error(`   âŒ ì‘ì—… ${job.id} ì˜ˆì™¸:`, err.message)
                    })
                    activeJobs.set(job.id, jobPromise)

                    // If we still have capacity, try claiming more immediately
                    if (activeJobs.size < MAX_CONCURRENT_JOBS) {
                        continue // Skip the sleep, try to claim another right away
                    }
                } else {
                    if (activeJobs.size > 0) {
                        process.stdout.write(`[${activeJobs.size} active]`)
                    } else {
                        process.stdout.write('.')
                    }
                }
                consecutiveErrors = 0
            } else {
                process.stdout.write(`[${activeJobs.size}/${MAX_CONCURRENT_JOBS} full]`)
            }
        } catch (error) {
            consecutiveErrors++
            console.error(`\n[${new Date().toLocaleTimeString()}] âš ï¸ í´ë§ ì˜¤ë¥˜ (${consecutiveErrors}/${MAX_CONSECUTIVE_ERRORS}):`, error.message)

            // If too many consecutive errors, restart browser
            if (consecutiveErrors >= MAX_CONSECUTIVE_ERRORS) {
                console.log('ğŸ”„ ì—°ì† ì˜¤ë¥˜ í•œê³„ ë„ë‹¬ â€” ë¸Œë¼ìš°ì € ì¬ì‹œì‘...')
                try {
                    if (browser) { await browser.close(); browser = null }
                } catch { browser = null }
                isLoggedIn = false
                consecutiveErrors = 0

                // Wait longer before next attempt
                await new Promise(r => setTimeout(r, POLL_INTERVAL_MS * 3))
                continue
            }
        }
        await new Promise(r => setTimeout(r, POLL_INTERVAL_MS))
    }
}

// Graceful shutdown
process.on('SIGINT', async () => {
    console.log('\nğŸ›‘ ì¢…ë£Œ ì¤‘...')
    if (browser) await browser.close()
    process.exit(0)
})

pollLoop().catch(err => { console.error('ì¹˜ëª…ì  ì˜¤ë¥˜:', err); process.exit(1) })
