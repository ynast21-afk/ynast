/**
 * kStreamer Folder Watcher â€” ë°”íƒ•í™”ë©´ í´ë” ê°ì‹œ ìë™ ì—…ë¡œë“œ
 * 
 * ì§€ì • í´ë”ì— ì˜ìƒ íŒŒì¼ì„ ë„£ìœ¼ë©´ ìë™ìœ¼ë¡œ íì— ì¶”ê°€í•©ë‹ˆë‹¤.
 * Firebaseì— ì§ì ‘ ì—°ê²° (Vercel API ìš°íšŒ)
 */

require('dotenv').config()
require('dotenv').config({ path: require('path').join(__dirname, '.env.local') })
const fs = require('fs')
const path = require('path')
const os = require('os')
const { addJob, getStreamers } = require('./firebase-direct')

// ============================================
// Configuration
// ============================================
const SITE_URL = process.env.SITE_URL || process.env.NEXT_PUBLIC_SITE_URL || 'http://localhost:3000'
const ADMIN_TOKEN = process.env.ADMIN_TOKEN || process.env.ADMIN_API_SECRET || ''
const WATCH_DIR = process.env.WATCH_DIR || path.join(os.homedir(), 'Desktop', 'kstreamer-upload')
const VIDEO_EXTENSIONS = ['.mp4', '.mkv', '.avi', '.mov', '.webm', '.ts', '.flv']
const STABILIZE_INTERVAL_MS = 2000 // File size check interval
const STABILIZE_CHECKS = 3         // Number of stable checks before processing

console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸ“‚ kStreamer Folder Watcher            â•‘
â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘  ê°ì‹œ í´ë”: ${WATCH_DIR.substring(0, 30).padEnd(30)}â•‘
â•‘  ì˜ìƒ í™•ì¥ì: ${VIDEO_EXTENSIONS.join(', ').substring(0, 27).padEnd(27)}â•‘
â•‘  ì„œë²„: ${SITE_URL.substring(0, 35).padEnd(35)}â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`)

// ============================================
// Create watch directory if it doesn't exist
// ============================================
if (!fs.existsSync(WATCH_DIR)) {
    fs.mkdirSync(WATCH_DIR, { recursive: true })
    console.log(`ğŸ“ ê°ì‹œ í´ë” ìƒì„±: ${WATCH_DIR}`)
}

// Create done subfolder
const DONE_DIR = path.join(WATCH_DIR, 'done')
if (!fs.existsSync(DONE_DIR)) {
    fs.mkdirSync(DONE_DIR, { recursive: true })
}

// Track files being processed to avoid duplicates
const processingFiles = new Set()
const processedFiles = new Set()

// ============================================
// API Request helper (used only for non-Firebase endpoints)
// ============================================
async function apiRequest(endpoint, method = 'GET', body = null) {
    const url = `${SITE_URL}${endpoint}`
    const options = {
        method,
        headers: { 'Content-Type': 'application/json', 'x-admin-token': ADMIN_TOKEN },
    }
    if (body) options.body = JSON.stringify(body)
    const res = await fetch(url, options)
    if (!res.ok) {
        const text = await res.text()
        throw new Error(`API ${method} ${endpoint} failed (${res.status}): ${text}`)
    }
    return res.json()
}

// ============================================
// Extract streamer info from filename
// ============================================
async function matchStreamerFromFilename(filename) {
    const baseName = path.basename(filename, path.extname(filename)).toLowerCase()

    try {
        // Read streamers via Vercel API
        const streamers = await getStreamers()

        // Sort by name length (longest first) for most specific match
        const sorted = streamers.sort((a, b) =>
            (b.name?.length || 0) - (a.name?.length || 0)
        )

        for (const s of sorted) {
            if (baseName.includes(s.id?.toLowerCase()) ||
                baseName.includes(s.name?.toLowerCase()) ||
                (s.koreanName && baseName.includes(s.koreanName.toLowerCase()))) {
                return { streamerId: s.id, streamerName: s.name }
            }
        }
    } catch (e) {
        console.warn(`   âš ï¸ ìŠ¤íŠ¸ë¦¬ë¨¸ ë§¤ì¹­ ì‹¤íŒ¨:`, e.message)
    }

    return { streamerId: null, streamerName: null }
}

// ============================================
// Wait for file to stabilize (copy complete)
// ============================================
function waitForStableFile(filePath) {
    return new Promise((resolve, reject) => {
        let lastSize = -1
        let stableCount = 0

        const check = setInterval(() => {
            try {
                if (!fs.existsSync(filePath)) {
                    clearInterval(check)
                    reject(new Error('File disappeared'))
                    return
                }

                const currentSize = fs.statSync(filePath).size

                if (currentSize === lastSize && currentSize > 0) {
                    stableCount++
                    if (stableCount >= STABILIZE_CHECKS) {
                        clearInterval(check)
                        resolve(currentSize)
                    }
                } else {
                    stableCount = 0
                    lastSize = currentSize
                }
            } catch {
                // File might be locked during copy
                stableCount = 0
            }
        }, STABILIZE_INTERVAL_MS)

        // Timeout after 10 minutes
        setTimeout(() => {
            clearInterval(check)
            reject(new Error('File stabilization timeout'))
        }, 600000)
    })
}

// ============================================
// Process a new file
// ============================================
async function processNewFile(filePath) {
    const fileName = path.basename(filePath)
    const ext = path.extname(fileName).toLowerCase()

    // Skip non-video files
    if (!VIDEO_EXTENSIONS.includes(ext)) return

    // Skip if already processing or processed
    if (processingFiles.has(filePath) || processedFiles.has(filePath)) return

    // Skip files in done/ folder
    if (filePath.includes(path.sep + 'done' + path.sep)) return

    processingFiles.add(filePath)
    console.log(`\nğŸ“¥ ìƒˆ ì˜ìƒ ê°ì§€: ${fileName}`)

    try {
        // Wait for file copy to complete
        console.log(`   â³ íŒŒì¼ ì•ˆì •í™” ëŒ€ê¸° ì¤‘...`)
        const fileSize = await waitForStableFile(filePath)
        console.log(`   âœ… íŒŒì¼ ì•ˆì •í™” ì™„ë£Œ: ${(fileSize / 1024 / 1024).toFixed(1)}MB`)

        // Extract streamer info from filename
        const { streamerId, streamerName } = await matchStreamerFromFilename(fileName)
        if (streamerName) {
            console.log(`   ğŸ‘¤ íŒŒì¼ëª…ì—ì„œ ìŠ¤íŠ¸ë¦¬ë¨¸ ê°ì§€: ${streamerName}`)
        } else {
            console.log(`   ğŸ‘¤ íŒŒì¼ëª…ì—ì„œ ìŠ¤íŠ¸ë¦¬ë¨¸ ë¯¸ê°ì§€ (ì›Œì»¤ì—ì„œ ì¶”ê°€ ë§¤ì¹­ ì‹œë„)`)
        }

        // Add to queue with local:// prefix â€” direct to Firestore
        const localUrl = `local://${filePath}`
        const jobId = `local-${Date.now()}-${Math.random().toString(36).substring(2, 8)}`
        const job = {
            id: jobId,
            sourceUrl: localUrl,
            status: 'queued',
            title: path.basename(filePath, path.extname(filePath)),
            titleSource: 'fileName',
            streamerId: streamerId || null,
            streamerName: streamerName || null,
            pageNumber: null,
            itemOrder: null,
            priority: 0,
            b2Url: null,
            b2ThumbnailUrl: null,
            error: null,
            progress: 0,
            workerId: null,
            lockedAt: null,
            createdAt: new Date().toISOString(),
            updatedAt: new Date().toISOString(),
            retryCount: 0,
        }

        await addJob(job)
        console.log(`   âœ… íì— ì¶”ê°€ ì™„ë£Œ! (ID: ${jobId})`)
        processedFiles.add(filePath)
    } catch (err) {
        if (err.code === 'DUPLICATE_JOB') {
            console.log(`   â­ï¸ ì´ë¯¸ ëŒ€ê¸°ì—´ì— ìˆëŠ” íŒŒì¼ì…ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤: ${fileName}`)
            processedFiles.add(filePath) // Mark as processed so we don't retry
        } else {
            console.error(`   âŒ ì²˜ë¦¬ ì‹¤íŒ¨:`, err.message)
        }
    } finally {
        processingFiles.delete(filePath)
    }
}

// ============================================
// Scan existing files on startup
// ============================================
async function scanExistingFiles() {
    try {
        const files = fs.readdirSync(WATCH_DIR)
        const videoFiles = files.filter(f => {
            const ext = path.extname(f).toLowerCase()
            return VIDEO_EXTENSIONS.includes(ext)
        })

        if (videoFiles.length > 0) {
            console.log(`ğŸ“‚ ê¸°ì¡´ ì˜ìƒ ${videoFiles.length}ê°œ ë°œê²¬, íì— ì¶”ê°€ ì¤‘...`)
            for (const file of videoFiles) {
                await processNewFile(path.join(WATCH_DIR, file))
            }
        }
    } catch (e) {
        console.error('ê¸°ì¡´ íŒŒì¼ ìŠ¤ìº” ì‹¤íŒ¨:', e.message)
    }
}

// ============================================
// Retry failed uploads (scan failed/ folder)
// ============================================
const RETRY_INTERVAL_MS = 5 * 60 * 1000 // 5 minutes

async function retryFailedFiles() {
    const failedDir = path.join(WATCH_DIR, 'failed')
    if (!fs.existsSync(failedDir)) return

    try {
        const files = fs.readdirSync(failedDir)
        const videoFiles = files.filter(f => VIDEO_EXTENSIONS.includes(path.extname(f).toLowerCase()))

        if (videoFiles.length === 0) return

        console.log(`\nğŸ”„ failed/ í´ë”ì—ì„œ ${videoFiles.length}ê°œ íŒŒì¼ ì¬ì‹œë„ ì¤‘...`)
        for (const file of videoFiles) {
            const failedPath = path.join(failedDir, file)
            const retryPath = path.join(WATCH_DIR, file)

            // Skip if a file with same name is already in watch dir or being processed
            if (fs.existsSync(retryPath) || processingFiles.has(retryPath)) continue

            try {
                // Remove from processedFiles set so it can be re-processed
                processedFiles.delete(retryPath)
                fs.renameSync(failedPath, retryPath)
                console.log(`   ğŸ” ì¬ì‹œë„: ${file}`)
            } catch (e) {
                console.warn(`   âš ï¸ ì¬ì‹œë„ ì´ë™ ì‹¤íŒ¨: ${file}`, e.message)
            }
        }
    } catch (e) {
        console.warn('failed/ í´ë” ìŠ¤ìº” ì‹¤íŒ¨:', e.message)
    }
}

// ============================================
// Start watching
// ============================================
async function startWatching() {
    // Scan existing files first
    await scanExistingFiles()

    // Watch for new files
    console.log(`\nğŸ‘€ í´ë” ê°ì‹œ ì‹œì‘... (${WATCH_DIR})`)
    console.log(`   ì˜ìƒ íŒŒì¼ì„ ì´ í´ë”ì— ë„£ìœ¼ë©´ ìë™ìœ¼ë¡œ ì—…ë¡œë“œë©ë‹ˆë‹¤.`)
    console.log(`   ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼ì€ done/ í´ë”ë¡œ ì´ë™ë©ë‹ˆë‹¤.`)
    console.log(`   ì‹¤íŒ¨í•œ íŒŒì¼ì€ failed/ í´ë”ë¡œ ì´ë™ í›„ 5ë¶„ë§ˆë‹¤ ìë™ ì¬ì‹œë„ë©ë‹ˆë‹¤.\n`)

    // Debounce map to prevent duplicate events from OS
    const debounceTimers = new Map()

    const watcher = fs.watch(WATCH_DIR, (eventType, filename) => {
        if (!filename) return

        const filePath = path.join(WATCH_DIR, filename)
        const ext = path.extname(filename).toLowerCase()

        if (eventType === 'rename' && VIDEO_EXTENSIONS.includes(ext)) {
            // Skip if already processing or processed
            if (processingFiles.has(filePath) || processedFiles.has(filePath)) return

            // Debounce: cancel previous timer for same file, set new one
            if (debounceTimers.has(filePath)) {
                clearTimeout(debounceTimers.get(filePath))
            }

            debounceTimers.set(filePath, setTimeout(() => {
                debounceTimers.delete(filePath)
                if (fs.existsSync(filePath) && !processingFiles.has(filePath) && !processedFiles.has(filePath)) {
                    processNewFile(filePath)
                }
            }, 3000))
        }
    })

    watcher.on('error', (err) => {
        console.error('ê°ì‹œ ì˜¤ë¥˜:', err.message)
    })

    // Periodically retry failed uploads
    setInterval(() => retryFailedFiles(), RETRY_INTERVAL_MS)

    // Keep alive
    process.on('SIGINT', () => {
        console.log('\nğŸ‘‹ í´ë” ê°ì‹œ ì¢…ë£Œ')
        watcher.close()
        process.exit(0)
    })
}

startWatching()
